\section{Constrained Optimization: Lagrange Multipliers}\label{sec:Lagrange}

At the end of the previous section, we explored \textit{constrained optimization}, \index{Constrained Optimization} a problem where we seek an extremum, but the variables are constrained to only take on values that satisfy some condition.  The method demonstrated in the previous section involves using the constraint equation to eliminate a variable from the function we want to optimize.  In this section, we explore a different method for solving constrained optimization problems.  The method is named after Joseph-Loius Lagrange, a famous Italian mathematician who lived in the 1700 and 1800s, and is called the method of Lagrange Multipliers.

\vskip\baselineskip
\noindent\textbf{\large Lagrange Multipliers: A Graphical Interpretation}
\vskip\baselineskip

For visualization purposes, we'll explore the method by way of a specific example involving a function of two variables.  We seek to find the maximum value of the function $f(x,y) = 1 - x^2 - y^2$ subject to the constraint $x + y = 1.$  A representation of the problem is shown in figure \ref{fig:3D_constrained}.  Without the constraint, the maximum is clearly given by $z=1$ when $x = y = 0.$  The constraint forces us to only consider $x$ and $y$ values such that $x + y = 1$. This constraint is drawn as a dashed line in the $x-y$ plane, and as a solid curve on the surface.  Essentially, we must walk along the red curve in figure \ref{fig:3D_constrained}(a) until we find its highest point.  Notice that as we walk along the constraint curve, we cross level curves of the function $f$.  Crossing a level curve means we're going uphill or downhill.  In other words, the places where $f$ is maximized (or minimized) subject to the constraint must be places where the constraint curve (often expressed as $g(x,y)=0$) is tangent to a level curve of the function $f(x,y)$. We see this more clearly in figure \ref{fig:3D_constrained}(b).

Now, in order for two curves to be tangent at a point, their normal vectors must be parallel. (They must either point in the same or opposite directions.) We know from section \ref{sec:directional_derivative} that the gradient $\nabla f(x_0,y_0)$ is orthogonal to the level curve of $f$ passing through the point $(x_0,y_0)$.  Further, since $x+y=1$ is simply the zero level curve of the function $g(x,y)=x+y-1$, the vector $\nabla g(x,y)$ is orthogonal to the constraint curve.  Therefore, we need a point $(x_0,y_0)$ on the constraint curve $x+y=1$ such that $\nabla f(x_0,y_0)$ and $\nabla g(x_0,y_0)$ are scalar multiples of each other (parallel vectors).  We state these requirements explicitly in theorem \ref{thm:Lagrange}.  The example following the theorem formalizes the arguments given above while making use of many of the concepts from this chapter.

\mtable{.55}{Graphing the level curves function $f(x,y)=1-x^2-y^2$ along with the constraint $x + y = 1$.}{fig:3D_constrained}{%
	\begin{tabular}{c}
		\myincludegraphics[scale=1]{figures/fig12_09_3D_constrained}\\
		(a)\\[15pt]
		\myincludegraphics[scale=1]{figures/fig12_09_3D_constrained_b}\\
		(b)
	\end{tabular}
}

\theorem{thm:Lagrange}{Lagrange's Theorem}
{Let $f(x,y)$ and $g(x,y)$ be differentiable at the point $(x_0,y_0)$.  If $f(x,y)$ has a local minimum or maximum subject to the constraint $g(x,y)=0$ at the point $(x_0,y_0)$ and if $\nabla g(x_0,y_0) \neq \vec{0}$, then there exists a scalar $\lambda$ such that
	\[
		\nabla f(x_0,y_0) = \lambda \nabla g(x_0,y_0).
	\]
The scalar $\lambda$ is called a \emph{Lagrange multiplier}. \index{Lagrange multiplier}\index{method of Lagrange multipliers}
}

\example{ex_Lagrange_proof}{A proof of Lagrange's Theorem}{
Use tools from this chapter to prove Lagrange's theorem.}
{Assume that $f(x,y)$ is maximized (or minimized) subject to the constraint $g(x,y)=0$ at the point $(x_0,y_0)$.  Let $\vec{r}(t)$ be a vector-valued function description of the constraint curve $g(x,y)=0$ such that $\vec{r}(t_0)=\la x_0,y_0 \ra$ and $\vec{r}'(t_0) \neq \vec{0}.$  Since $\vec{r}(t)$ describes the constraint curve, $f(\vec{r}(t))$, for varying $t$ values, corresponds to walking along the surface $z=f(x,y)$ along the path given by the constraint $g(x,y)=0$. (This is the red curve from figure \ref{fig:3D_constrained}(a).)By assumption $f(\vec{r}(t_0))$ is an extreme value.  Thus $\fp(\vec{r}(t)) = 0$ when $t = t_0$.  Using the multivariable chain rule from section \ref{sec:multi_chain} to expand the derivative, this is
	\[
		\nabla f(x_0,y_0) \cdot \vec{r}'(t_0)=0.
	\]
We now have two options. The first is that $\nabla f(x_0,y_0) = \vec{0}.$  In this case, the statement of Lagrange's theorem is easily satisfied by choosing $\lambda = 0.$

The second option is that $\nabla f(x_0,y_0) \neq \vec{0}.$ In this second case, the vectors $\nabla f(x_0,y_0)$ and $\vec{r}'(t_0)$ must be orthogonal.  We know from section \ref{sec:vvf_calc} that $\vec{r}'(t_0)$ is tangent to the curve $\vec{r}(t)$.  It follows that $\nabla f(x_0,y_0)$ must be orthogonal to $\vec{r}(t_0)$, which is a vector tangent to the constraint curve $g(x,y)=0$ at the point $(x_0,y_0)$. Finally, the constraint curve $g(x,y)=0$ is simply the zero level curve of the function $g(x,y)$.  From section \ref{sec:directional_derivative}, we know that $\nabla g(x_0,y_0)$ is orthogonal to the level curve of $g$ at $(x_0,y_0)$. So then $\nabla f(x_0,y_0)$ and $\nabla g(x_0,y_0)$ are \emph{both} orthogonal to the same vector, and must be parallel.  It follows that
	\[
		\nabla f(x_0,y_0) = \lambda \nabla g(x_0,y_0)
	\] 
for some scalar $\lambda$.
}

\vskip\baselineskip
\noindent\textbf{\large Using the Method of Lagrange Multipliers}
\vskip\baselineskip

Though the previous example puts Lagrange's theorem on solid theoretical footing, it doesn't give us an explicit description for how to solve a constrained optimization problem.  Key idea \ref{idea:Lagrange_method} describes how to use Lagrange's theorem to solve actual problems.
\enlargethispage{2\baselineskip}

\keyidea{idea:Lagrange_method}{The Method of Lagrange Multipliers}
{Suppose $f(x,y)$ and $g(x,y)$ satisfy the requirements of Lagrange's Theorem.  Suppose further that $f(x,y)$ has a maximum or minimum subject to the constraint $g(x,y)=0$. To find the maximum or minimum of $f(x,y)$
	\begin{enumerate}
		\item Calculate $\nabla f(x,y)$ and $\nabla g(x,y)$.  Then solve the system of equations 3 equations
		\[
			\left \{ \begin{array}{rl}  f_x(x,y) &= \lambda g_x(x,y)\\
										f_y(x,y) &= \lambda g_y(x,y)\\
										g(x,y) &= 0 \\\end{array} \right .
		\]
		for $x$ and $y$.
		\item Evaluate $f(x,y)$ at each of the solutions points found in step 1.  The largest yields the maximum value of $f(x,y)$ subject to the constraint, and the smallest yields the minimum value.
	\end{enumerate}
}

We start by solving the example presented at the beginning of the section.

\example{ex_Lagrange1}{Using Lagrange Multipliers}{
	Find the maximum of $f(x,y) = 1-x^2-y^2$ subject to the constraint $x+y=1$.}
{We first identify the constraint function as $g(x,y) = x+y-1$.  Calculating the gradients, $\nabla f(x,y) = \la -2x,-2y \ra$ and $\nabla g(x,y) = \la 1,1 \ra.$  We seek to solve the system of equations
	\[
	\left \{
	\begin{array}{rl}
		     -2x & = \lambda  \\
			-2y	 & = \lambda  \\
		  x+y & = 1
	\end{array} \right .
	\]
In general, solving a system of equations can be quite difficult, especially if the equations are nonlinear. There is not one single solution process,and there may be many answers.  Here, the equations are relatively simple, and are easy to solve. Taken together, the first two equations imply $-2x=-2y$ or $x=y$.  Using this information in the third equation yields $x+x=1$ or $x=1/2$.  Thus the point $(1/2,1/2)$ maximizes $f(x,y) = 1-x^2-y^2$ subject to the constraint $x+y=1$, and yields a maximum value of $1/2.$
}

\mnote{.45}{\textbf{Caution:} Recall from theorem \ref{thm:extreme_val3} that we can only guarantee that $f(x,y)$ attains a maximum and minimum value if it is continuous on a closed, bounded set $S$. Here, the constraint $x+y=1$ is not closed and bounded. Therefore, we can't guarantee that $f(x,y)=1-x^2-y^2$ attains both a maximum and minimum on $x+y=1$.  In fact, figure \ref{fig:3D_constrained}(a) shows clearly that $f(x,y)$ has a maximum, but no minimum.  The steps in key idea \ref{idea:Lagrange_method} describe how to find relative maxima and minima, but do not guarantee anything about absolute maximum or minimum values.  Graphic reasoning is often helpful to interpret the results from key idea \ref{idea:Lagrange_method}.}

\vskip\baselineskip

\example{ex_lagrange_closed}{Using Lagrange Multipliers}{
	Find the maximum and minimum values of $f(x,y)=4xy$ subject to the constraint $\dfrac{x^2}{9} + \dfrac{y^2}{4} = 1$.}
{We first note that $\dfrac{x^2}{9} + \dfrac{y^2}{4} = 1$ is an ellipse, which is a closed and bounded region. According to the extreme value theorem, $f(x,y) = 4xy$ will attain both its minimum and maximum values somewhere on the constraint curve. To apply the method of Lagrange multipliers, we first calculate $\nabla f(x,y) = \la 4y, 4x \ra$ and $\nabla g(x,y) = \la \dfrac{2x}{9}, \dfrac{y}{2} \ra.$ We need to solve the system of equations
	\[
	\left \{
	\begin{array}{rl}
	4y & = \dfrac{2\lambda x}{9}  \\
	4x	 & = \dfrac{\lambda y}{2}  \\
	\dfrac{x^2}{9} + \dfrac{y^2}{4} & = 1
	\end{array} \right .
	\]
Unlike the previous example, this system of equations is nonlinear more difficult to solve.  Though there are many paths to the solution, we start by rewriting the first two equations as $18y = \lambda x$ and $8x = \lambda y.$  Multiplying the first by $y$ and the second by $x$, we have $18y^2 = \lambda yx$ and $8x^2 = \lambda xy$, which means that $18y^2 = 8x^2$.  Solving for $x^2$, we have $x^2 = \dfrac{9}{4}y^2$.  We can substitute this into the constraint equation to get $\dfrac{\frac{9}{4}y^2}{9} + \dfrac{y^2}{4} = 1.$ We easily solve this equation to get $y^2 = 2$ or $y = \pm \sqrt{2}$. Substituting back into $x^2 = \dfrac{9}{4}y^2$, we have $x^2 = \dfrac{9}{2}$ or $x = \pm \dfrac{3}{\sqrt{2}}.$ All combinations of these $x$ and $y$ values yields the 4 points
	\[
		\left ( -\frac{3}{\sqrt{2}},-\sqrt{2}\right), 	\left ( -\frac{3}{\sqrt{2}},\sqrt{2}\right), 	\left ( \frac{3}{\sqrt{2}},-\sqrt{2}\right), \text{ and } 	\left ( \frac{3}{\sqrt{2}},\sqrt{2}\right).
	\]
Evaluating $f(x,y) = 4xy$ at these 4 points, we have
	\[
	f\left ( -\frac{3}{\sqrt{2}},-\sqrt{2}\right) = f\left ( \frac{3}{\sqrt{2}},\sqrt{2}\right) = 12
	\]
and
	\[
		f\left ( -\frac{3}{\sqrt{2}},\sqrt{2}\right) = f\left ( \frac{3}{\sqrt{2}},-\sqrt{2}\right) = -12.
	\]
We see that $f(x,y) = 4xy$ has two maximum and two minimum values on the elliptic constraint $\dfrac{x^2}{9} + \dfrac{y^2}{4} = 1$. Figure \ref{fig:lagrange_closed} shows this result graphically.
}

\mfigure{.4}{Visualization of $f(x,y) = 4xy$ subject to $\dfrac{x^2}{9} + \dfrac{y^2}{4} = 1$.}{fig:lagrange_closed}{figures/fig12_09_lagrange_closed}
%\mfigure{.75}{Illustrating the domain of $f(x,y)$ in Example \ref{ex_multi2}.}{fig:multi2}{figures/figmulti2}

%\printexercises{exercises/12_07_exercises}
